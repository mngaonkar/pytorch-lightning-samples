{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4116ac0f-7ba6-4db6-874e-c859270c1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lightning as L\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import optim, nn, utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2a397925-6e6a-480d-9003-43c5963e8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encoder\n",
    "encoder = nn.Sequential(\n",
    "    nn.Linear(in_features=28*28, out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64, out_features=32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e2e9c36d-7546-43a2-bc46-94e2f0015bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define decoder\n",
    "decoder = nn.Sequential(\n",
    "    nn.Linear(in_features=32, out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64, out_features=28*28)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7628b53-c3d5-4315-9322-6302fd7ccb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lightning class\n",
    "class AutoEncoder(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = nn.functional.mse_loss(x_hat, x)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "df9b97cf-67d0-49e3-866d-f7f8ce8f45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate lightning object\n",
    "autoenc = AutoEncoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "32c5ed72-beef-4ca3-b2c9-89cec37e991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset\n",
    "dataset = MNIST(root=\"./mnist\", download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dfd78449-9cfe-4b84-af09-65396e17934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data in data loader\n",
    "train_dataloader = utils.data.DataLoader(dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1e5996c6-12e8-4f24-8716-ba838613c160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# create trainer\n",
    "trainer = L.Trainer(max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "225b3b47-4eeb-40e8-8dfc-a839b5fbfe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | encoder | Sequential | 52.3 K | train\n",
      "1 | decoder | Sequential | 53.1 K | train\n",
      "-----------------------------------------------\n",
      "105 K     Trainable params\n",
      "0         Non-trainable params\n",
      "105 K     Total params\n",
      "0.422     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575a0a0c9995430b949397f09d0a1910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    }
   ],
   "source": [
    "# rock n roll\n",
    "trainer.fit(model=autoenc, train_dataloaders=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5c0b0c5b-ca02-4a02-b73b-e50a349f51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "checkpoint = \"./lightning_logs/version_20/checkpoints/epoch=49-step=46900.ckpt\"\n",
    "auto_enc_predictor = AutoEncoder.load_from_checkpoint(checkpoint, encoder=encoder, decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "62edfca3-e76f-4d43-9a99-936c9cf56095",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = auto_enc_predictor.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4f6d34b0-c417-4c7a-9f6d-dfbc7439d088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "88065ab3-e4d9-482b-8020-9fc9ee9c9fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image = dataset[1][0]\n",
    "val_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "656e4648-039f-4611-8465-ca2d0949e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder(val_image.reshape(1, 28*28).to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ae59a3e6-ef41-4a48-a3ca-fbc208313a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0517, -0.1728,  0.3324, -0.3902,  0.3861, -0.3323,  0.5353,  0.0907,\n",
       "         -0.3645, -0.2934, -0.5721, -0.3519,  0.5203,  0.2456,  0.2726,  0.0493,\n",
       "          0.0163,  0.3854, -0.1200,  0.1472,  0.3729, -1.0473,  0.1514,  0.0176,\n",
       "          0.4674, -0.1703, -0.2916,  1.5344, -0.1018, -0.1906, -0.4269,  0.0600]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6b91db29-4df9-45d6-b307-d425a11c4917",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = auto_enc_predictor.decoder(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ff16150c-64cf-42c8-b370-41ae8dafbb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display decoded image\n",
    "image = decoded.reshape(28, 28).to(\"cpu\").detach().numpy()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bfba77a3-9c5a-4faa-a959-9f3eb4568d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAACWlJREFUeJzt3M+LluUex/HrSVEUcRZuEoZ2tdQxKdwZLTMocBFDOFtBgiFiFsEY7YLQIIUkEMFQMKJFEyFuJty4ktE/wFWIA9kQpQQGdZ/V+RCcA+f5Xmd+Ob5e6+fDfTvOzNtr4TUahmFoANBae26jXwCAzUMUAAhRACBEAYAQBQBCFAAIUQAgRAGA2D7uB0ej0Vq+BwBrbJz/q+ykAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQ2zf6BeBpdvjw4fLmvffe63rWzMxMefPVV1+VN+fPny9vlpaWyhs2JycFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBgNwzCM9cHRaK3fBTbU1NRUebO4uFje7N27t7xZT7/99lt5s2/fvjV4E1bbOL/unRQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAYvtGvwCshVdffbW8+fbbb8ubiYmJ8mbMOyj/w6NHj8qbP//8s7zpudzuyJEj5c3S0lJ501rfn4nxOSkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAxGgY83au0Wi01u/CFrd79+6u3csvv1zeXLlypbyZnJwsb3p+LnovxOu5QO7TTz8tb65du1be9Hwd5ufny5vWWvvkk0+6doz3veekAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEBs3+gX4Nnx5Zdfdu2mp6dX+U2eTj23xe7Zs6e8uXnzZnnz2muvlTcHDhwob1h7TgoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA4UI8uhw+fLi8OXbsWNezRqNR166q5yK477//vrw5c+ZMedNaaw8ePChv7ty5U978+uuv5c3rr79e3qzX3ys1TgoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAMRqGYRjrgy6v2rKmpqbKm8XFxfJm79695U2v69evlzfT09PlzdGjR8ubAwcOlDettXbx4sXy5uHDh13Pqvrrr7/Kmz/++KPrWT1f86Wlpa5nbTXj/Lp3UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACI7Rv9Aqyul156qbyZm5srbyYmJsqbX375pbxprbXl5eXy5vLly+XN48ePy5sffvhhXTZb0a5du7p2H3zwQXnz7rvvdj3rWeSkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4JXWT2rlzZ9fuzJkz5c0bb7xR3jx69Ki8mZmZKW9aa+327dvlTe8NnGx+L7zwwka/wpbmpABAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQLsTbpA4dOtS167ncrsdbb71V3ty8eXMN3gRYTU4KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOFCvE3qs88+69qNRqPypueiOpfb8U/PPVf/9+Xff/+9Bm/C/8tJAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBciLcO3nzzzfJmamqq61nDMJQ3CwsLXc+Cf+u53K7ne7W11u7evdu1YzxOCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDhQrx1sGvXrvJmx44dXc/6+eefy5uvv/6661lsfjt37ixvPv7449V/kf9icXGxa/fhhx+u8pvwT04KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIRbUreYJ0+elDfLy8tr8Castp4bT+fn58ububm58ub+/fvlzdmzZ8ub1lp7/Phx147xOCkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhAvxtpiFhYWNfgX+h6mpqa5dz0V177zzTnnz3XfflTfHjx8vb9icnBQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAwoV462A0Gq3LprXW3n777fJmdna261m09v7775c3p0+f7nrWxMREeXP16tXyZmZmprxh63BSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAgX4q2DYRjWZdNaa88//3x5c+7cufLm0qVL5c3Kykp501prR44cKW9OnDhR3hw8eLC8mZycLG9++umn8qa11m7cuFHefPHFF13P4tnlpABAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQLsTbYrZt21benDp1qrw5fvx4efP777+XN6219uKLL3bt1sOtW7fKmx9//LHrWR999FHXDiqcFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACI0TAMw1gfHI3W+l22rMnJyfLmm2++6XrWK6+80rWr6vl+GPNbbVWsrKyUN9euXStvZmdnyxvYKOP8DDopABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQL8Tap/fv3d+1OnjxZ3szPz5c363kh3ueff17eXLhwoby5d+9eeQNPExfiAVAiCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4EA/gGeFCPABKRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiO3jfnAYhrV8DwA2AScFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUA4l8iMS/g/NuB/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display original image\n",
    "plt.imshow(val_image.reshape(28, 28).numpy(), cmap='gray')\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4689ec-571a-4e44-87ba-087aa8c29ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ecd8ec-2586-4713-b747-e34229b5a911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
