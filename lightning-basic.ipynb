{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49aa8db8-6842-4e56-b2ad-1e0fff6f9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "02f7bdb4-e8c7-40c0-a53c-d14051d2141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a lightning class\n",
    "class NN(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=50, out_features=10)\n",
    "        )\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_hat = self.model(x)\n",
    "        return y_hat\n",
    "\n",
    "    def _step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        return loss\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = _step(batch, batch_idx)\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        y_hat = self.forward(x)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "737084d5-8811-4c68-a2be-8b1f9e6fc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ced9de0b-5251-4671-805e-916397499bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8849b9e4-e015-47b8-96bf-0beb83240053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_data = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dd9f262e-75db-46aa-b0e1-6dea948dfd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b012ebbf-3b6a-4b45-88ba-8128cfc08d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data loader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f06f632c-e8c2-421f-bf17-856fcc77f496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = torch.Size([64, 1, 28, 28])\n",
      "y shape = torch.Size([64])\n",
      "x type = <class 'torch.Tensor'>\n",
      "y type = <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for item in train_loader:\n",
    "    print(f\"x shape = {item[0].shape}\")\n",
    "    print(f\"y shape = {item[1].shape}\")\n",
    "    print(f\"x type = {type(item[0])}\")\n",
    "    print(f\"y type = {type(item[1])}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b21e3816-ae19-4932-8500-ebaaa8983ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lightning model\n",
    "model = NN(input_size=28*28, num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "69987656-aec9-43cd-8701-f52d4cbe863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | Sequential       | 39.8 K | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "39.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "39.8 K    Total params\n",
      "0.159     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705efc96f1d84879a2a63effd568fded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09d2f16e88543eba908155b391755c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1785e5ab3e2e4469bb70a42a520472f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8ba3f2e08b4cb8b782e1a2c626ce9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a77be65efa0410ca774f70fbc6a1b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3338074351ef4b27b46c24c2a0df2e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e3373a933940f19024aa9d5d2e2aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc537c7634b4665aa15c5a1faf82b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7023460172364f91ae98fcf6e7291cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a trainer and fit\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=[0], max_epochs=10)\n",
    "trainer.fit(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "85adc8b4-2c4a-4e3c-976f-3199ab535b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer number from a test image\n",
    "input_image = test_data[1][0]\n",
    "preds = model(input_image.reshape(28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8cac516e-7a1b-46e2-90ab-378fb68fec6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -3.9316,   3.7321,   9.6028,   1.4504, -18.6409,  -4.8391,  -2.9120,\n",
      "        -21.1585,  -2.7298, -16.5233], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(preds)\n",
    "torch.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d20c4a50-5b6d-4a31-8308-3b4841b45e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display input image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = input_image.reshape(28, 28).to(\"cpu\").detach().numpy()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f2e19-c756-4fb3-9ad6-c101a3c11452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
